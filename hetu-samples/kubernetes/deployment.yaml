# Copyright (C) 2020. Huawei Technologies Co., Ltd. All rights reserved.
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

#### openlk namespace ####
---
apiVersion: v1
kind: Namespace
metadata:
  name: openlk

#### openLooKeng service ####
---
apiVersion: v1
kind: Service
metadata:
  name: openlk
  namespace: openlk
spec:
  type: NodePort
  ports:
  - port: 8080
    targetPort: 8080
    nodePort: 30321
  selector:
    app: openlk-coordinator

#### coordinator ####
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: openlk-coordinator
  namespace: openlk
spec:
  replicas: 1
  selector:
    matchLabels:
      app: openlk-coordinator
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 0%
  template:
    metadata:
      labels:
        app: openlk-coordinator
    spec:
      # TODO: enable if graceful shutdown is needed
      # terminationGracePeriodSeconds: 3600
      containers:
      - name: openlk-coordinator
        image: openlookeng:{{ imageTag }}
        imagePullPolicy: IfNotPresent
        # Update "jvmXmx" value according to memory allocation below. Suggest 60~70% of total memory limit.
        args: ["-t", "coordinator", "-configDir", "/custom-configs", "-jvmXmx", "1300M"]
        resources:
          requests:
            cpu: 1
            memory: 2G
          limits:
            cpu: 1
            memory: 2G
        # TODO: enable if graceful shutdown is needed
        # lifecycle:
        #   preStop:
        #     exec:
        #       command:
        #       - /usr/lib/hetu/bin/shutdown-hetu
        volumeMounts:
        - mountPath: /custom-configs
          name: custom-configs-volume
      volumes:
      - name: custom-configs-volume
        hostPath:
          # TODO: update to point to additional configuration and catalog folder
          path: /hetu-core/hetu-samples/kubernetes/config-coordinator

#### worker ####
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: openlk-worker
  namespace: openlk
spec:
  replicas: 2
  selector:
    matchLabels:
      app: openlk-worker
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 0%
  template:
    metadata:
      labels:
        app: openlk-worker
    spec:
      # TODO: enable if graceful shutdown is needed
      # terminationGracePeriodSeconds: 600
      containers:
      - name: openlk-worker
        image: openlookeng:{{ imageTag }}
        imagePullPolicy: IfNotPresent
        # Update "jvmXmx" value according to memory allocation below. Suggest 60~70% of total memory limit.
        args: ["-t", "worker", "-discoveryURI", "http://openlk:8080", "-configDir", "/custom-configs", "-jvmXmx", "1300M"]
        resources:
          requests:
            cpu: 1
            memory: 2G
          limits:
            cpu: 1
            memory: 2G
        # TODO: enable if graceful shutdown is needed
        # lifecycle:
        #   preStop:
        #     exec:
        #       command:
        #       - /usr/lib/hetu/bin/shutdown-hetu
        volumeMounts:
        - mountPath: /custom-configs
          name: custom-configs-volume
      volumes:
      - name: custom-configs-volume
        hostPath:
          # TODO: update to point to additional configuration and catalog folder
          path: /hetu-core/hetu-samples/kubernetes/config-worker

# TODO: enable for coordinator auto-scaling
#### HPA for coordinator ####
# ---
# apiVersion: autoscaling/v2beta2
# kind: HorizontalPodAutoscaler
# metadata:
#   name: openlk-coordinator-scaler
#   namespace: openlk
# spec:
#   scaleTargetRef:
#     apiVersion: apps/v1
#     kind: Deployment
#     name: openlk-coordinator
#   minReplicas: 1
#   maxReplicas: 2
#   metrics:
#   - type: Resource
#     resource:
#       name: cpu
#       target:
#         type: Utilization
#         averageUtilization: 50
#       # TODO: other scaling conditions, e.g. memory
#   behavior:
#     scaleDown:
#       stabilizationWindowSeconds: 300

# TODO: enable for worker auto-scaling
#### HPA for worker ####
# ---
# apiVersion: autoscaling/v2beta2
# kind: HorizontalPodAutoscaler
# metadata:
#   name: openlk-worker-scaler
#   namespace: openlk
# spec:
#   scaleTargetRef:
#     apiVersion: apps/v1
#     kind: Deployment
#     name: openlk-worker
#   minReplicas: 1
#   maxReplicas: 5
#   metrics:
#   - type: Resource
#     resource:
#       name: cpu
#       target:
#         type: Utilization
#         averageUtilization: 50
#       # TODO: other scaling conditions, e.g. memory
#   behavior:
#     scaleDown:
#       stabilizationWindowSeconds: 300
